{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b51445dc-e013-463b-9473-948e6150a27d",
   "metadata": {},
   "source": [
    "# Spam Classification Lab\n",
    "_Georgetown Certificate in Data Science_\n",
    "_Module 1: Foundations of Data Science_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860e7bae-178b-4dfd-a183-c147523e4ceb",
   "metadata": {},
   "source": [
    "## Lab Overview\n",
    "\n",
    "This lab will go through the steps of the data science pipeline that we covered in class. In class, we talked about building a classification model that could distinguish between `relevant` and `not relevant` news articles. This lab will be similar, although not exactly the same: we'll build a **spam classifier**. \n",
    "\n",
    "### The Task, and the Data\n",
    "- We'll use a training dataset from the UC Irvine Machine Learning repository, which is a great resource for learning. The dataset consists of a few thousand text messages, some of which are spam. Our objective is to train a machine learning model capable of distinguishing between `spam` and `not spam` (referred to as `ham`).\n",
    "- You can find the dataset [here](https://archive.ics.uci.edu/dataset/94/spambase).\n",
    "- We'll finish up the lab by building a lightweight web application that you can use to see what kinds of predictions our model makes with any text message you can think of! This part is optional, and it's okay if the code doesn't all make sense -- but it's a good exercise in understanding how we might consider making our machine learning models useful after we've put so much work into them. \n",
    "\n",
    "## Data Science Pipeline\n",
    "\n",
    "As a reminder, the steps in our data science pipeline are:\n",
    "\n",
    "1. **Data Ingestion**: The initial step in which we acquire our data, typically by downloading it, using APIs, or from some data repository.\n",
    "2. **Munging and Wrangling**: Preprocessing of data where we handle missing values, outliers, and structure it in a way that makes it suitable for analysis. This may also include storing the data in databases.\n",
    "3. **Computation and Analysis (EDA)**: We explore our data using statistics and visual tools to understand its characteristics, distribution, and relationships.\n",
    "4. **Modeling and Application**: We apply algorithms to build predictive or classification models, and then we evaluate these models to check their performance.\n",
    "5. **Reporting and Visualization**: Finally, we communicate our findings, whether that's via reports, visuals, dashboards, or other applications. This is where we translate our technical findings into actionable business insights.\n",
    "\n",
    "Perhaps unsurprisingly, that's also the flow of this lab. Let's get started!\n",
    "\n",
    "## Student Tasks\n",
    "The sections of that lab for you to complete are marked with this header:\n",
    "> ### ðŸ“Œ Task: _____\n",
    "\n",
    "Under each Task, there's an empty code block with instructions and space for you to complete the task. Good luck, and have fun!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecacf5e-7511-4564-8af8-586d315ae2ad",
   "metadata": {},
   "source": [
    "# 0. Import relevant Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabd1837-f76c-42c9-b45b-9e844ccccf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "# Machine learning models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Machine learning utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0491925-556f-4b18-8838-00e04cd1f247",
   "metadata": {},
   "source": [
    "## 1. Data Ingestion\n",
    "We'll download the data and open it in Pandas. We can either download a file that we store on our computer's disk, or we can use the URL where the file is hosted and download it straight into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf540b74-c205-46f4-8fa1-27f5bb7e99ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's download the data directly from where the data is hosted\n",
    "# Pandas has a utility to download files directly from the internet,\n",
    "# which is cool. Notice that it's a tab-delimited file -- the \n",
    "# extension ends in \".tsv\". So we just let Pandas know that by using the \n",
    "# \"delimiter\" argument.\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/justmarkham/DAT8/master/data/sms.tsv\"\n",
    "df = pd.read_csv(url, delimiter='\\t', header=None, names=['label', 'message'])\n",
    "\n",
    "# Let's peek at our data\n",
    "df.head()\n",
    "\n",
    "# Alternatively, you could download the file from the internet:\n",
    "# https://archive.ics.uci.edu/dataset/228/sms+spam+collection\n",
    "# Then you could and save the file locally and read it using code like this:\n",
    "\n",
    "# spam_path = \"data/SMSSpamCollection\" # I saved it in a directory called \"data\"\n",
    "# df = pd.read_csv(spam_path, header=None, delimiter=\"\\t\", names=[\"label\", \"message\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3163bf0-5943-487c-957b-5356fe1a9484",
   "metadata": {},
   "source": [
    "# Munging and Wrangling\n",
    "\n",
    "For this lab, the dataset is quite clean. But let's start by understanding the distribution of our labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896467b7-6180-4747-b950-7260aad5acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the distribution of labels\n",
    "label_dist = df['label'].value_counts()\n",
    "label_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1588c4f-c0eb-4849-9699-976fb8d94c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaa11d8-4e69-4eed-9cf4-5c543eb5cf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How we might remove rows with missing values:\n",
    "# df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4362e3-28e3-445b-8b59-b50a34baf0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing textual data with a placeholder text\n",
    "# sms_data['text'].fillna('missing', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d14379-f516-4d30-b370-fe92b9c3122b",
   "metadata": {},
   "source": [
    "### ðŸ“Œ Task: Munging and Wrangling - Deduplicating Data\n",
    "In any dataset, duplicated rows can skew analysis and predictions. It's crucial to ensure data is clean and deduplicated. In this task, you will remove any duplicated rows from your dataframe.\n",
    "\n",
    "Objective: Identify and remove any duplicate rows from the df dataframe.\n",
    "Steps:\n",
    "1. Identify the number of duplicate rows.\n",
    "2. Remove the duplicates.\n",
    "3. Verify that duplicates have been removed.\n",
    "\n",
    "There are multiple ways to accomplish this task; you just need to find one that works! \n",
    "_Hint: Pandas documentation is a great place to find the answer._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80814c6-4c6e-454d-81a8-cefd2853efef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Identify the number of duplicate rows\n",
    "# TODO: Your code here to identify duplicates\n",
    "\n",
    "# STEP 2: Remove the duplicates\n",
    "# TODO: Your code here to remove duplicates\n",
    "\n",
    "# STEP 3: Verify that duplicates have been removed\n",
    "# TODO: Your code here to verify removal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4c8c89-e03e-4ca6-8678-404136d1be1f",
   "metadata": {},
   "source": [
    "### Investigating Data Quality Issues\n",
    "Besides missingness, there might be other data quality issues to consider, such as:\n",
    "\n",
    "- Inconsistent text data: Especially in textual datasets, it might be common to find different forms of the same word (e.g., U.S.A. vs. USA).\n",
    "- Outliers: While more relevant for numerical data, in textual data, a message with a very large number of characters might be a system error or spam.\n",
    "- Unbalanced classes: In our context, we might have far more 'ham' messages than 'spam', which might impact the performance of our machine learning models.\n",
    "\n",
    "This section provides a basic overview of checking for data quality issues. In practice, this process might be more iterative and might require more domain-specific considerations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acda566-b0f5-4d37-9aa5-f25d720a1a6c",
   "metadata": {},
   "source": [
    "## Computation and Analysis\n",
    "Let's visualize the distribution of message lengths and the breakdown of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cf0de3-5e73-444e-90b7-aa29d8f2f635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of message lengths\n",
    "df['text_length'] = df['message'].apply(len)\n",
    "df['text_length'].hist(bins=50)\n",
    "plt.title('Distribution of Message Lengths')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Number of Messages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae61e68e-af8c-4746-b028-b16eaf454d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breakdown of \"spam\" vs \"ham\" labels\n",
    "label_dist.plot(kind='bar')\n",
    "plt.title('Distribution of Labels')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Number of Messages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391bb15c-115f-4253-b9d8-6238395182f4",
   "metadata": {},
   "source": [
    "### Trying a different visualiation library: Plotly\n",
    "\n",
    "Matplotlib is a great library, but there are very, very many visualization options. Here's a look at the library Plotly. Note that you interact with this library in a slightly different way, and there are generally fewer lines of code involved. The visualizations are also interactive, and they're rendered as HTML: if you hover over a data point, you can see information in a \"tooltip\". The documentation goes into much more detail, if you're interested: https://plotly.com/python/. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a830e8c-7120-4748-8ea1-ae7868161b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram using Plotly\n",
    "fig_length = px.histogram(df, x='text_length', title='Distribution of Message Lengths', nbins=50)\n",
    "fig_length.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be31100e-e81b-4b9c-8b3b-1fbe39399a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot using Plotly\n",
    "fig_box = px.box(df, x='label', y='text_length', points=\"all\", title=\"Message Length by Label\")\n",
    "fig_box.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a111d89-2f06-4e79-b2bb-c59baa0f4f0d",
   "metadata": {},
   "source": [
    "### ðŸ“Œ Task: Create Another Visualization of Your Data or Model\n",
    "Data visualization provides insights that might not be immediately apparent from raw data. Create another visualization of your choice that you find insightful.\n",
    "\n",
    "Objective: Explore your data or model outcomes with a new visualization.\n",
    "\n",
    "Steps:\n",
    "1. Choose a type of plot or chart that you find interesting.\n",
    "2. Implement the visualization using matplotlib or plotly.\n",
    "3. Interpret your visualization briefly.\n",
    "_Hint: matplotlib and plotly documentation offer many examples._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6c2c18-87c7-4cd5-87ff-0c1681c35fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Choose a visualization type (e.g. scatter plot, histogram, etc.)\n",
    "\n",
    "# STEP 2: Implement the visualization\n",
    "# Example: plt.hist(df['column_name'])\n",
    "# TODO: Your code here\n",
    "\n",
    "# STEP 3: Interpretation\n",
    "# TODO: Write down your insights below this cell after creating the visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27518dc-1eea-4289-8c01-8e2f0363d0bd",
   "metadata": {},
   "source": [
    "### Data Transformation\n",
    "Once we're satisfied with the cleanliness and quality of your data, it might be necessary to transform it to better suit your analysis or modeling needs.\n",
    "\n",
    "For our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e46955-423a-4f37-8d9a-b494f6c89c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll need to convert labels to numerical values (e.g., 'ham' to 0 and 'spam' to 1)\n",
    "df['label_num'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# Checking the first few rows to see our changes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9500c1a4-24f1-40bc-bbe6-c26161bb09ca",
   "metadata": {},
   "source": [
    "# Modeling and Application\n",
    "\n",
    "We'll try two approaches to the actual machine learning portion of this lab: \n",
    "1. A **\"steel thread\"**. The \"steel thread\" approach is extremely basic: it involves minimal feature engineering, no hyperparameter tuning -- but it results in a model that is capable of making predictions. The idea is that regardless of how good or not-yet-good our model is, as long as it's complete and working, we can have a fully functional data science pipeline that spans from ingestion to reporting. \n",
    "2. A refined pass at improving our modeling. This builds on the steel thread, incrementally improving it. We might use better feature engineering (perhaps with a method like TF-IDF) and attempt a pass at hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0b339d-136f-4359-b2ae-56916cd6524f",
   "metadata": {},
   "source": [
    "### Simple Steel Thread\n",
    "No-frills, straightforward, probably-not-exceptionally-impressive, minimal example of how we might format our data into something a model can understand, then use it to actually train a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9adf504-6c8b-4edd-b27a-ab7db213c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['message'], df['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ed960-927d-483c-84f6-135818887a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using CountVectorizer to transform our text data\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train_transformed = vectorizer.fit_transform(X_train)\n",
    "X_test_transformed = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Naive Bayes model\n",
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bafe4b8-9257-44c0-a673-28e2cb8e4e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one line of code is where the machine learning happens\n",
    "clf.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf38df65-c3a5-46d6-b0af-7c8f1574207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "y_pred = clf.predict(X_test_transformed)\n",
    "\n",
    "# Evaluating our model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f6c44b-684f-4811-9137-0e192480a9ef",
   "metadata": {},
   "source": [
    "### Slightly more refined pass \n",
    "\n",
    "Let's try again with a couple of different models, and let's compare them. We'll also evaluate which model performs the best, using F1 as the metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00ee458-5375-47aa-8c0d-2d469cf40088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TfidfVectorizer\n",
    "vectorizer_tfidf = TfidfVectorizer(stop_words='english')\n",
    "X_train_transformed_tfidf = vectorizer_tfidf.fit_transform(X_train)\n",
    "X_test_transformed_tfidf = vectorizer_tfidf.transform(X_test)\n",
    "\n",
    "# Comparing different models: Naive Bayes, Random Forest, and Logistic Regression\n",
    "models = [\n",
    "    ('Naive Bayes', MultinomialNB()),\n",
    "    ('Random Forest', RandomForestClassifier(random_state=42)),\n",
    "    ('Logistic Regression', LogisticRegression(random_state=42))\n",
    "]\n",
    "\n",
    "best_f1 = 0\n",
    "best_model_name = ''\n",
    "best_model = None\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train_transformed_tfidf, y_train)\n",
    "    y_pred = model.predict(X_test_transformed_tfidf)\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"Results for {name}\")\n",
    "    \n",
    "    # Output formatted for printing\n",
    "    print(classification_report(y_test, y_pred, output_dict=False))\n",
    "    print(\"------------------------------\")\n",
    "    \n",
    "    # Determine if this model has the highest F1 score\n",
    "    report = classification_report(y_test, y_pred, output_dict=True) # output formatted as a dict this time\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_model_name = name\n",
    "        best_model = model\n",
    "\n",
    "# Save the best model to disk using pickle\n",
    "filename = 'best_model.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "\n",
    "print(f\"The best model is {best_model_name} with F1 score of {best_f1:.2f}. Model saved as {filename}.\")\n",
    "\n",
    "# # Also save the vectorizer, which is already fitted to our training data\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(vectorizer_tfidf, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2fdaa9-3527-4cb8-80c0-c07fa912de61",
   "metadata": {},
   "source": [
    "### ðŸ“Œ Task: Train Another Classifier\n",
    "Scikit-learn offers a plethora of algorithms. Research and choose another classifier to train on your data.\n",
    "\n",
    "Objective: Train a different classifier from the ones used in the lab.\n",
    "\n",
    "Steps:\n",
    "1. Research and choose another classifier from scikit-learn.\n",
    "2. Train the classifier using the training data.\n",
    "3. Validate its performance with the test data.\n",
    "_Hint: The scikit-learn documentation has a list of available classifiers._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798323c3-7fd7-4e8b-b51e-8add66c81f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.some_module import YourChosenClassifier  # Replace some_module and YourChosenClassifier appropriately\n",
    "\n",
    "# STEP 1: Choose another classifier -- something like:\n",
    "clf = YourChosenClassifier()\n",
    "\n",
    "# STEP 2: Train the classifier\n",
    "# TODO: Your code here\n",
    "\n",
    "# STEP 3: Validate its performance\n",
    "# TODO: Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd3cbbf-39db-449f-b0ec-2b0edc420614",
   "metadata": {},
   "source": [
    "### ðŸ“Œ Task: Generate Confusion Matrix for Your Classifier\n",
    "A confusion matrix provides a summary of the prediction results for a classification problem.\n",
    "\n",
    "Objective: Generate a confusion matrix for the classifier you trained.\n",
    "\n",
    "Steps:\n",
    "1. Predict the class labels for the test set.\n",
    "2. Generate the confusion matrix.\n",
    "\n",
    "_Hint: we just did this earlier -- you can use the same syntax._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d069924-6df0-4be2-87de-db5b9f55f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Predict class labels for the test set\n",
    "# TODO: Your code here\n",
    "\n",
    "# STEP 2: Generate the confusion matrix\n",
    "# TODO: Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa0de4d-6bcd-4311-8178-9aedd2c07e46",
   "metadata": {},
   "source": [
    "# Visual Model Diagnostics\n",
    "\n",
    "Visualization isn't just something we do at the end of a project -- it can help us understand what's happening behind the scenes with our machine learning models. Instead of viewing our classfication reports as tables, let's visualize them using the Yellowbrick library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4234a31-f872-4b37-a071-6f6f6a050195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(X_train, y_train, X_test, y_test, model_name, estimator):\n",
    "    \"\"\"\n",
    "    Visualize performance of an estimator using Yellowbrick's ClassificationReport.\n",
    "    \"\"\"\n",
    "    # Ensure labels are properly encoded\n",
    "    y_train_encoded = LabelEncoder().fit_transform(y_train)\n",
    "    y_test_encoded = LabelEncoder().fit_transform(y_test)\n",
    "    \n",
    "    # Create a pipeline with TfidfVectorizer and the estimator\n",
    "    model = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "        ('estimator', estimator)\n",
    "    ])\n",
    "\n",
    "    # Instantiate the classification model and visualizer\n",
    "    visualizer = ClassificationReport(\n",
    "        model, classes=['ham', 'spam'],\n",
    "        cmap=\"YlGn\", size=(600, 360)\n",
    "    )\n",
    "    visualizer.fit(X_train, y_train_encoded)\n",
    "    visualizer.score(X_test, y_test_encoded)\n",
    "    visualizer.show(title=f\"Classification Report for {model_name}\")\n",
    "\n",
    "# Loop over each model and visualize\n",
    "for name, model in models:\n",
    "    visualize_model(X_train, y_train, X_test, y_test, name, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5a7e68-0e62-486f-a70f-5c55ad505a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_confusion_matrix(X_train, y_train, X_test, y_test, model_name, estimator):\n",
    "    \"\"\"\n",
    "    Visualize confusion matrix of an estimator using Yellowbrick's ConfusionMatrix.\n",
    "    \"\"\"\n",
    "    # Ensure labels are properly encoded\n",
    "    y_train_encoded = LabelEncoder().fit_transform(y_train)\n",
    "    y_test_encoded = LabelEncoder().fit_transform(y_test)\n",
    "    \n",
    "    # Create a pipeline with TfidfVectorizer and the estimator\n",
    "    model = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "        ('estimator', estimator)\n",
    "    ])\n",
    "\n",
    "    # Instantiate the confusion matrix visualizer\n",
    "    visualizer = ConfusionMatrix(\n",
    "        model, classes=['ham', 'spam'],\n",
    "        cmap=\"YlGn\", size=(600, 360)\n",
    "    )\n",
    "    visualizer.fit(X_train, y_train_encoded)\n",
    "    visualizer.score(X_test, y_test_encoded)\n",
    "    visualizer.show(title=f\"Confusion Matrix for {model_name}\")\n",
    "\n",
    "# Loop over each model and visualize the confusion matrix\n",
    "for name, model in models:\n",
    "    visualize_confusion_matrix(X_train, y_train, X_test, y_test, name, model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f691dc3b-41c2-4186-b32a-3b2511827ea5",
   "metadata": {},
   "source": [
    "# Reporting and Visualization \n",
    "\n",
    "We're going to use a library called Streamlit to write an extremely basic Python application. We'll use the application to serve our model!\n",
    "\n",
    "This part of the lab isn't \"on the test\", so to speak -- the certificate program isn't focused on building web apps. The cell below contains a lot that you may not understand yet -- that's perfectly fine. You don't need to know all of this right now. But if you want to, it's a good idea to try to read the code and follow along with what it's doing. You can also play around with adjusting parts of it and seeing how it changes the application we're building.\n",
    "\n",
    "### An aside: `%%writefile` syntax\n",
    "Note that the cell starts with some strange syntax that doens't look like Python: `%%writefile spam_app.py`. This line is actually instructing the Jupyter notebook to creating a new Python file. The two percentage signs are an example of something called \"Jupyter magic\" -- they're just little tools that help folks who use Jupyter notebooks be more productive or communicate more clearly. In this example, I could have just included a file called `spam_app.py` and instructed you to open it, but doing it this way contains our entire lab to this single notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5840c4a2-31d9-436b-b3c3-b66da0b16df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile spam_app.py\n",
    "\n",
    "import streamlit as st\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load the pickled model and vectorizer\n",
    "with open('best_model.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "with open('tfidf_vectorizer.pkl', 'rb') as file:\n",
    "    vectorizer = pickle.load(file)\n",
    "\n",
    "def highlight_important_features(model, vectorizer, text):\n",
    "    \"\"\"\n",
    "    Extract and rank important features (words) from the given text based on the model's feature importances.\n",
    "\n",
    "    Parameters:\n",
    "    - model (sklearn.base.BaseEstimator): A trained machine learning model, \n",
    "                                          currently supporting Logistic Regression and Random Forest.\n",
    "    - vectorizer (sklearn.feature_extraction.text.TfidfVectorizer): A fitted TF-IDF vectorizer.\n",
    "    - text (str): The input text from which to extract and rank important words.\n",
    "\n",
    "    Returns:\n",
    "    - list[tuple[str, float]]: A list of tuples where each tuple represents a word from the text and its \n",
    "                               corresponding importance. The list is sorted by importance in descending order, \n",
    "                               with the most important word first. The importance metric differs based on the model:\n",
    "                                   - Logistic Regression: Coefficient values.\n",
    "                                   - Random Forest: Feature importances (mean decrease impurity).\n",
    "                               Only the top 10 important words are returned.\n",
    "\n",
    "    Notes:\n",
    "    - For Logistic Regression, the coefficients represent how a one-unit change in the predictor affects \n",
    "      the log odds of the response variable being 1.\n",
    "    - For Random Forest, the importances are computed as the mean decrease impurity, a measure of how much \n",
    "      a feature contributes to the overall prediction accuracy.\n",
    "    \"\"\"\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    # For Logistic Regression\n",
    "    if isinstance(model, LogisticRegression):\n",
    "        coefficients = model.coef_[0]\n",
    "        tokens = vectorizer.transform([text])\n",
    "        important_words = [(feature_names[index], coefficients[index]) for index in tokens.indices]\n",
    "        \n",
    "    # For Random Forest\n",
    "    elif isinstance(model, RandomForestClassifier):\n",
    "        importances = model.feature_importances_\n",
    "        tokens = vectorizer.transform([text])\n",
    "        important_words = [(feature_names[index], importances[index]) for index in tokens.indices]\n",
    "\n",
    "    # For Multinomial Naive Bayes\n",
    "    elif isinstance(model, MultinomialNB):\n",
    "        log_probabilities = model.feature_log_prob_ \n",
    "        # For binary classification, class `1` is usually the spam class\n",
    "        spam_class_index = list(model.classes_).index(1)\n",
    "        tokens = vectorizer.transform([text])\n",
    "        important_words = [(feature_names[index], log_probabilities[spam_class_index][index]) for index in tokens.indices]\n",
    "\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "    # Sort words by importance\n",
    "    important_words = sorted(important_words, key=lambda x: -abs(x[1]))\n",
    "    return important_words[:10]\n",
    "\n",
    "\n",
    "\n",
    "# Define the main function for the Streamlit app\n",
    "def main():\n",
    "    st.title(\"Spam Detection App\")\n",
    "    st.write(\"Enter a sample SMS text message. Our model will predict whether it's spam or ham:\")\n",
    "\n",
    "    # Get user input\n",
    "    user_input = st.text_area(\"Message\", \"\")\n",
    "    \n",
    "    # Create a predict button and when it's clicked, predict the class of the input text\n",
    "    if st.button(\"Predict\"):\n",
    "        # Transform the user input text using the Tfidf vectorizer\n",
    "        user_input_transformed = vectorizer.transform([user_input])\n",
    "        \n",
    "        # Use the loaded model to make a prediction\n",
    "        prediction = model.predict(user_input_transformed)[0]\n",
    "        prediction_proba = model.predict_proba(user_input_transformed)\n",
    "        \n",
    "        # Display prediction and confidence\n",
    "        if prediction == \"spam\":\n",
    "            st.write(f\"The message is predicted to be: **Spam** with a confidence of {prediction_proba[0][1]:.2%}\")\n",
    "        else:\n",
    "            st.write(f\"The message is predicted to be: **Ham** with a confidence of {prediction_proba[0][0]:.2%}\")\n",
    "            \n",
    "        # Let's have our app display the words that are most important \n",
    "        # to our model's predictions. See the highlight_important_features() function\n",
    "        # above for more details.\n",
    "        important_words = highlight_important_features(model, vectorizer, user_input)\n",
    "        if important_words:\n",
    "            # Convert the list of tuples into a DataFrame\n",
    "            df_important_words = pd.DataFrame(important_words, columns=[\"Word\", \"Importance\"])\n",
    "            # Sort the dataframe by Importance, in descending order to have the most important words at the top\n",
    "            df_important_words = df_important_words.sort_values(by=\"Importance\", ascending=False)\n",
    "            st.write(\"Words contributing to the prediction:\")\n",
    "            # Display the table in Streamlit\n",
    "            st.table(df_important_words)\n",
    "\n",
    "# Run the app. These two lines allow our file to be run from the command line\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cae87b-4c91-4568-b452-b7a3b912d8bf",
   "metadata": {},
   "source": [
    "### Executing our application\n",
    "\n",
    "The cell below has an exclamation point at the beginning, which is just Jupyter syntax for saying `run this line in my command line interface`. E.g., if you ran `!ls` in a Jupyter cell, the output would list the contents of your current working directory. \n",
    "\n",
    "In this case, we're simply instructing the program `streamlit` to `run` the file that we created in the previous cell, `spam_app.py`. If everything goes as expected, your browser should open another tab with our lightweight application in it. \n",
    "\n",
    "Once it's up and running, test out what our model thinks about a few new text messages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cb4ab9-deb6-4054-8151-fa7437049df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run spam_app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d1eacc-87d6-448c-80a4-b81edc33771f",
   "metadata": {},
   "source": [
    "# Iterate and revise\n",
    "\n",
    "At this point, we've made a pass through the entire pipeline. But, if you remember from class, there's always room to improve!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce8645d-dba2-442a-94f8-2d6de205af2b",
   "metadata": {},
   "source": [
    "# Discussion Questions\n",
    "\n",
    "Congratulations -- in this lab, we've successfully taken a (brief) tour of the entire data science pipeline.\n",
    "\n",
    "Here are some good questions to consider for class. They won't be formally graded, but you'll get the most out of this exercise if you develop a perspective on each of these questions before we meet synchonously:\n",
    "1. What is our model good at, in terms of predicting `ham` vs `spam` text messages correctly? What is it less good at?\n",
    "2. If you had a few days to do nothing else but improve this workflow, where would you prioritize? Why?\n",
    "3. What would have happened to our model if we had not removed the duplicate rows when cleaning the data?\n",
    "4. We have a lot more examples of `ham` texts in our training data than `spam`. How might that affect the way our model makes decisions? Is there anything we can do about it?\n",
    "5. If given more data, particularly for the minority class, how do you think the performance of the model might change?\n",
    "6. Considering the context of SMS messages and the costs of misclassification: Is it worse to misclassify a ham as spam (false positive) or a spam as ham (false negative)? Why?\n",
    "7. In what real-world scenarios could such a spam classifier be applied? What would be the potential benefits and drawbacks?\n",
    "8. Our dataset includes short SMS messages. How might our model's performance be affected if we had to classify longer documents, like emails?\n",
    "9. How might slang or colloquial language play a role in the model's ability to correctly classify messages?\n",
    "10. With new slang, memes, and internet language evolving rapidly, how might the model handle these changes over time? How frequently should the model be updated?\n",
    "11. What ethical concerns could arise from automating spam classification? Consider both the technical and societal implications.\n",
    "\n",
    "## Closing note\n",
    "Remember: you don't need to have mastered all of this content yet. Please do not feel overwhelmed. Having said that, this is an excellent example of one of the points we try to make in class: that the primary skill of a data scientist is the ability to learn new skills. So if you're intrigued by how any of this works but don't totally understand it, feel free to go the the source: the documentation! The docs are the best way to learn about a new piece of technology.\n",
    "- [Jupyter magic documentation](https://ipython.readthedocs.io/en/stable/interactive/magics.html)\n",
    "- [Scikit-learn documentation](https://scikit-learn.org/stable/getting_started.html)\n",
    "- [Streamlit documentation](https://docs.streamlit.io/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
